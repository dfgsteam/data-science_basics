{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science I\n",
    "### Klausur I im Sommersemester 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeine Informationen\n",
    "\n",
    "* Sie haben eine Woche Zeit, um die Klausur zu bearbeiten.\n",
    "\n",
    "* Sie können alle Quellen verwenden, müssen sie jedoch korrekt benennen. Wenn Sie ChatGPT oder eine ähnliche Software verwenden, müssen Sie dies kenntlich machen und den verwendeten Prompt angeben.\n",
    "\n",
    "* Sie sollten die folgenden Pakete verwenden: `numpy, pandas, scipy, geopy, scikit-learn/sklearn, matplotlib, seborn, openPyxl` und Pythons Standardlibraries. Diese sind ausreichend, um die Klausur zu lösen. Falls Sie andere Pakete verwenden, rechtfertigen Sie deren Verwendung.\n",
    "\n",
    "* Der Code muss ausreichend kommentiert und verständlich sein. Schreiben Sie Funktionen beim Wiederverwenden von Code. Befolgen Sie im Allgemeinen die Richtlinien aus der Vorlesung. Punkte können aufgrund eines schlecht strukturierten oder unverständlichen Codes abgezogen werden.\n",
    "\n",
    "* **Begründen Sie Entscheidungen** zur Auswahl von Plots, Hypothesentest usw. und **interpretieren Sie** Ihre Ergebnisse.\n",
    "\n",
    "* Sie dürfen in keiner Form Hilfe oder Rat von Dritten in Anspruch nehmen.\n",
    "\n",
    "* Bitte laden Sie Ihre vollständige Lösung der Klausur als `.zip`-Datei mit dem Dateinamen `vorname_matrikelnummer.zip` bis 8. August 2024 um 12:00 Uhr auf StudIP in den Ordner `Submission - Exam 1` hoch.\n",
    "\n",
    "* Fügen Sie der `.zip` Datei auch die unterschriebene Eigenständigkeitserklärung hinzu.\n",
    "\n",
    "* Wenn Sie Fragen haben, kontaktieren Sie uns bitte rechtzeitig über Rocketchat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import numpy as np, pandas as pd, scipy, geopy, sklearn, matplotlib, seaborn, openpyxl, warnings, os \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='openpyxl')\n",
    "\n",
    "#import numpy, pandas, scipy, geopy, sklearn, matplotlib, seaborn, openPyxl, scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben und Punkte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th colspan=\"3\">Aufgabe 1 - Data Preprocessing</th>\n",
    "      <th colspan=\"2\">Aufgabe 2 - Plotting</th>\n",
    "      <th colspan=\"2\">Aufgabe 3 - Statistics</th>\n",
    "      <th colspan=\"2\">Aufgabe 4 - Machine Learning </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Aufgabe 1.1</th>\n",
    "      <th>Aufgabe 1.2</th>\n",
    "      <th>Aufgabe 1.3</th>\n",
    "      <th>Aufgabe 2.1</th>\n",
    "      <th>Aufgabe 2.2</th>\n",
    "      <th>Aufgabe 3.1</th>\n",
    "      <th>Aufgabe 3.2</th>\n",
    "      <th>Aufgabe 4.1</th>\n",
    "      <th>Aufgabe 4.2</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>10 Punkte </td>\n",
    "      <td>12 Punkte </td>\n",
    "      <td>2 Punkte </td>\n",
    "      <td>11 Punkte</td>\n",
    "      <td>27 Punkte </td>\n",
    "      <td>13 Punkte </td>\n",
    "      <td>5 Punkte </td>\n",
    "      <td>10 Punkte </td>\n",
    "      <td>10 Punkte </td>\n",
    "    </tr>\n",
    "    <!-- Add more rows as needed -->\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## Aufgabe 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Klausurordner enthält ein `Dockerfile`, in dem alle relevanten Pakete definiert sind. Das `Dockerfile` baut auf dem Jupyter Server Image auf. Verwenden Sie dieses Dockerfile, um zuerst ein Docker Image zu erstellen und dann einen Docker Container von diesem Image zu starten. Benutzen Sie anschließend die Jupyter Server Instanz, um an der Klausur zu arbeiten. Wir empfehlen dringend, die Docker-Umgebung zu verwenden, um Versionskonflikte zwischen den verschiedenen Paketen zu vermeiden. Code, der in dieser Umgebung nicht ausführbar ist, wird als **nicht funktional** bewertet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Aufgabe 1: Data Preprocessing (24 Punkte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenbeschreibung\n",
    "\n",
    "Im Ordner `data` finden Sie die monatlichen Parkdaten der Stadt Göttingen für das Jahr 2023 (Feb.-Dez.). Die Parkschein-Verkäufe an den stationären Parkscheinautomaten befinden sich in den Dateien, deren Namen mit `Cale` beginnt, und die mit der Parkster-App gekauften Parkscheine befinden sich in den Dateien, deren Namen mit `Parkster` beginnen.<br>\n",
    "Die Datei `parkzone_latlong.csv` enthält weitere geografische Informationen zu den Parkzonen und die Datei `psa_latlong.csv` enthält geografische Informationen über die Parkscheinautomaten innerhalb der Parkzone.\n",
    "\n",
    "Die bereitgestellten Parkdaten sind echte Rohdaten und stammen direkt von der Stadt Göttingen. Wir haben lediglich die geografischen Informationen hinzugefügt.\n",
    "\n",
    "*Bitte beachten Sie:*\n",
    "- *Obwohl wir nur Daten von Februar bis Dezember haben, bezeichnen wir diese im Folgenden als jährlich.*\n",
    "- *Aufgrund der Größe der Daten sollten Sie Ihren Arbeitsspeicher effizient verwenden. Vermeiden Sie daher die Speicherung mehrerer Kopien desselben DataFrames.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufagbe 1.1 - Laden der Daten (10 Punkte)\n",
    "Laden Sie die Dateien für die Parkscheinautomaten (`Cale-*`) und für die App (`Parkster-*`) und fügen Sie diese **jeweils** zu einem Dataframe zusammen, der die jährlichen Verkäufe für Parkscheinautomaten und App beinhaltet. <br>\n",
    "Laden Sie auch die weiteren Informationen zu den Parkscheinautomaten (`psa_latlong.csv`) und Parkzonen (` parkzones_latlong.csv`).\n",
    "\n",
    "Sie werden die Werte `0` und `999` in der Spalte `Automaten -ID` für die Daten der Parkscheinautomaten finden. <br> Ändern Sie die `0`en in `1`en und löschen Sie alle Einträge mit `999`.\n",
    "Überprüfen Sie auch auf Zeilen-Duplikate und löschen Sie diese gegebenenfalls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Automaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automaten starts\n",
      "automaten finish\n",
      "----------------\n",
      "      Automat - Automaten ID Zahleinheit - Name     Knoten  \\\n",
      "0                       PA22              Münze  Göttingen   \n",
      "1                       PA18              Münze  Göttingen   \n",
      "2                       PA76              Münze  Göttingen   \n",
      "3                       PA67              Münze  Göttingen   \n",
      "4                       PA75              Münze  Göttingen   \n",
      "...                      ...                ...        ...   \n",
      "60723                   PA12              Münze  Göttingen   \n",
      "60724                   PA94              Münze  Göttingen   \n",
      "60725                   PA27              Münze  Göttingen   \n",
      "60726                   PA22              Münze  Göttingen   \n",
      "60727                   PA27              Münze  Göttingen   \n",
      "\n",
      "           Kaufdatum Lokal  Betrag Artikelname  Artikel ID Tarifpaket - Name  \\\n",
      "0      01.06.2023 00:24:24     6.0  Parkticket           0      Normalticket   \n",
      "1      01.06.2023 00:27:39     4.2  Parkticket           0      Normalticket   \n",
      "2      01.06.2023 00:36:00     1.0  Parkticket           0      Normalticket   \n",
      "3      01.06.2023 01:11:26     1.0  Parkticket           0      Normalticket   \n",
      "4      01.06.2023 02:17:35     3.5  Parkticket           0      Normalticket   \n",
      "...                    ...     ...         ...         ...               ...   \n",
      "60723  30.11.2023 21:36:45     7.0  Parkticket           0      Normalticket   \n",
      "60724  30.11.2023 22:36:37     7.0  Parkticket           0      Normalticket   \n",
      "60725  30.11.2023 22:51:12     5.0  Parkticket           0      Normalticket   \n",
      "60726  30.11.2023 22:53:03     5.3  Parkticket           0      Normalticket   \n",
      "60727  30.11.2023 23:19:09     4.0  Parkticket           0      Normalticket   \n",
      "\n",
      "       Maskierter PAN  Transaktionsreferenz  Ticket Nummer  \n",
      "0                 NaN                   NaN           4951  \n",
      "1                 NaN                   NaN           3650  \n",
      "2                 NaN                   NaN           4413  \n",
      "3                 NaN                   NaN            887  \n",
      "4                 NaN                   NaN           1699  \n",
      "...               ...                   ...            ...  \n",
      "60723             NaN                   NaN           3800  \n",
      "60724             NaN                   NaN           2773  \n",
      "60725             NaN                   NaN           1775  \n",
      "60726             NaN                   NaN            204  \n",
      "60727             NaN                   NaN           1776  \n",
      "\n",
      "[708570 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data for Parkscheinautomaten\n",
    "print(\"automaten starts\")\n",
    "automaten_files = list(filter(lambda x: x.startswith('Cale-'), os.listdir('data')))\n",
    "automaten_df = pd.concat([pd.read_excel(f\"data/{file}\", skiprows=2) for file in automaten_files])\n",
    "print(\"automaten finish\\n----------------\")\n",
    "\n",
    "if debug: print(automaten_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote PA and convert number to int -> easier replacement + easier connection in task 1b\n",
    "automaten_df['Automat - Automaten ID'] = automaten_df['Automat - Automaten ID'].str.replace(\"PA\", \"\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app start\n",
      "app finish\n",
      "----------------\n",
      "       Parkzone             Erstellt                Start  \\\n",
      "0         37010  2023-02-28 08:00:27  2023-02-28 08:00:27   \n",
      "1         37010  2023-02-28 09:29:55  2023-02-28 09:29:55   \n",
      "2         37010  2023-02-28 15:18:57  2023-02-28 15:18:57   \n",
      "3         37005  2023-02-28 16:38:33  2023-02-28 16:38:33   \n",
      "4         37005  2023-02-28 16:45:17  2023-02-28 16:45:17   \n",
      "...         ...                  ...                  ...   \n",
      "32829     37108  2023-05-31 19:39:53  2023-05-31 19:39:53   \n",
      "32830     37204  2023-05-31 19:46:03  2023-05-31 19:46:03   \n",
      "32831     37104  2023-05-31 19:58:45  2023-05-31 19:58:45   \n",
      "32832     37001  2023-05-31 22:29:05  2023-05-31 22:29:05   \n",
      "32833     37001  2023-05-31 22:33:09  2023-05-31 22:33:09   \n",
      "\n",
      "                     Stopp  Parkgebühren inkl. MwSt. in EUR     Status  \\\n",
      "0      2023-03-01 00:00:27                             4.00     normal   \n",
      "1      2023-03-01 09:29:55                             4.00     normal   \n",
      "2      2023-03-01 15:18:57                             4.00     normal   \n",
      "3      2023-03-01 10:20:00                             3.28     normal   \n",
      "4      2023-03-01 07:45:17                             1.57     normal   \n",
      "...                    ...                              ...        ...   \n",
      "32829  2023-05-31 20:17:27                              NaN     normal   \n",
      "32830  2023-05-31 19:52:59                              NaN     normal   \n",
      "32831  2023-05-31 23:43:53                              NaN     normal   \n",
      "32832  2023-05-31 22:29:38                              NaN  storniert   \n",
      "32833  2023-05-31 22:33:28                              NaN  storniert   \n",
      "\n",
      "      Parkscheinart  Zonencode Eigentümercode  \n",
      "0          Kurzzeit      37010                 \n",
      "1          Kurzzeit      37010                 \n",
      "2          Kurzzeit      37010                 \n",
      "3          Kurzzeit      37005                 \n",
      "4          Kurzzeit      37005                 \n",
      "...             ...        ...            ...  \n",
      "32829      Kurzzeit      37108                 \n",
      "32830      Kurzzeit      37204                 \n",
      "32831      Kurzzeit      37104                 \n",
      "32832      Kurzzeit      37001                 \n",
      "32833      Kurzzeit      37001                 \n",
      "\n",
      "[381307 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data for App\n",
    "print(\"app start\")\n",
    "app_files = list(filter(lambda x: x.startswith('Parkster-'), os.listdir('data')))\n",
    "app_df = pd.concat([pd.read_excel(f\"data/{file}\") for file in app_files])\n",
    "app_df['Parkgebühren inkl. MwSt. in EUR'] = app_df['Parkgebühren inkl. MwSt. in EUR'].str.replace(',', '.').astype(float) # to compare floats\n",
    "print(\"app finish\\n----------------\")\n",
    "\n",
    "if debug: print(app_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Parkscheinautomaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkscheinautomaten start\n",
      "Parkscheinautomaten finish\n",
      "----------------\n",
      "       PSA                 location   latitude  longitude   zone\n",
      "0        1           Am Geismar Tor  51.529542   9.939956  37101\n",
      "1    1 - 2           Am Geismar Tor  51.529542   9.939956  37101\n",
      "2        2             Bürgerstraße  51.533104   9.926817  37102\n",
      "3        3                Papendiek  51.533827   9.931693  37001\n",
      "4        4       Bonifatiusschule -  51.528850   9.936085  37209\n",
      "..     ...                      ...        ...        ...    ...\n",
      "199    358          Kreuzbergring 2  51.542319   9.932972  37008\n",
      "200    359          Kreuzbergring 3  51.542898   9.933473  37008\n",
      "201    360  Von - Siebold- Straße 1  51.545994   9.943523  37008\n",
      "202    361  Von - Siebold- Straße 2  51.546472   9.943674  37008\n",
      "203    362  Von - Siebold- Straße 3  51.545665   9.942838  37008\n",
      "\n",
      "[204 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data for Parkscheinautomaten information\n",
    "print(\"Parkscheinautomaten start\")\n",
    "psa_info_df = pd.read_csv('data/psa_latlong.csv')\n",
    "print(\"Parkscheinautomaten finish\\n----------------\")\n",
    "\n",
    "if debug: print(psa_info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Parkzonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkzonen start\n",
      "Parkzonen finish\n",
      "----------------\n",
      "     latitude  longitude  Zonencode  \\\n",
      "0   51.534248   9.936501      37001   \n",
      "1   51.531270   9.936706      37005   \n",
      "2   51.541762   9.942282      37008   \n",
      "3   51.541249   9.944294      37009   \n",
      "4   51.553603   9.942338      37010   \n",
      "5   51.529542   9.939956      37101   \n",
      "6   51.533104   9.926817      37102   \n",
      "7   51.534678   9.942051      37103   \n",
      "8   51.536634   9.932465      37104   \n",
      "9   51.529205   9.933063      37105   \n",
      "10  51.530127   9.937980      37106   \n",
      "11  51.531365   9.927962      37107   \n",
      "12  51.536733   9.928201      37108   \n",
      "13  51.537675   9.930298      37109   \n",
      "14  51.533859   9.943545      37201   \n",
      "15  51.528115   9.940574      37202   \n",
      "16  51.528164   9.940557      37203   \n",
      "17  51.540630   9.935538      37204   \n",
      "18  51.537585   9.940781      37205   \n",
      "19  51.541593   9.937814      37206   \n",
      "20  51.528780   9.931563      37207   \n",
      "21  51.532833   9.935181      37208   \n",
      "22  51.528850   9.936085      37209   \n",
      "\n",
      "                                              Bereich Höchstparkdauer  \n",
      "0                  Parkzone I - Straßenrandparkplätze       4 Stunden  \n",
      "1                 Parkzone II - Straßenrandparkplätze       4 Stunden  \n",
      "2   Parkzone II - Humboldtallee, Nikolausberger We...       6 Stunden  \n",
      "3                               Parkzone II - Waldweg      11 Stunden  \n",
      "4          Parkzone II - Am Papenberg, Zimmermannstr.     Tagesticket  \n",
      "5              Parkzone I - Parkplatz Am Geismar Tor        4 Stunden  \n",
      "6                 Parkzone I - Parkplatz Bürgerstraße       4 Stunden  \n",
      "7                  Parkzone I - Parkplatz Albaniplatz       8 Stunden  \n",
      "8              Parkzone I - Parkplatz Reitstallstraße       4 Stunden  \n",
      "9         Parkzone I - Parkplatz Bürgerstraße / Juzi        4 Stunden  \n",
      "10                 Parkzone I - Parkplatz Rosengarten      10 Stunden  \n",
      "11            Parkzone I - Parkplatz Voigt Realschule       4 Stunden  \n",
      "12                 Parkzone I - Parkplatz Bahnhof Ost        1 Stunde  \n",
      "13              Parkzone I - Parkplatz Justizbehörden       4 Stunden  \n",
      "14                 Parkzone II - Parkplatz Stadthalle       4 Stunden  \n",
      "15                  Parkzone II - Parkplatz Rathaus I       4 Stunden  \n",
      "16    Parkzone II - Parkplatz Rathaus II + Tiefgarage       4 Stunden  \n",
      "17  Parkzone II - Parkplatz Platz der Göttinger Si...       8 Stunden  \n",
      "18         Parkzone II - Parkplatz M-P-G / Sporthalle       8 Stunden  \n",
      "19               Parkzone II - Parkplatz Goßlerstraße       8 Stunden  \n",
      "20        Parkzone II - Parkplatz FKG Bürgerstraße 36       4 Stunden  \n",
      "21  Parkzone II - Parkplatz Landkreis (Freitags ab...       4 Stunden  \n",
      "22  Parkzone II - Parkplatz Bonifatiusschule I (nu...       4 Stunden  \n"
     ]
    }
   ],
   "source": [
    "# Load data for Parkzonen information\n",
    "print(\"Parkzonen start\")\n",
    "parkzone_info_df = pd.read_csv('data/parkzones_latlong.csv')\n",
    "print(\"Parkzonen finish\\n----------------\")\n",
    "if debug: print(parkzone_info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove and replace Automaten-IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 0s to 1s in Automaten -ID column\n",
    "automaten_df['Automat - Automaten ID'] = automaten_df['Automat - Automaten ID'].replace(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop entry with id 999\n",
    "automaten_df = automaten_df[automaten_df['Automat - Automaten ID'] != 999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and drop duplicate rows\n",
    "automaten_df = automaten_df.drop_duplicates()\n",
    "app_df = app_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Automat - Automaten ID', 'Zahleinheit - Name', 'Knoten',\n",
      "       'Kaufdatum Lokal', 'Betrag', 'Artikelname', 'Artikel ID',\n",
      "       'Tarifpaket - Name', 'Maskierter PAN', 'Transaktionsreferenz',\n",
      "       'Ticket Nummer'],\n",
      "      dtype='object')\n",
      "Index(['Parkzone', 'Erstellt', 'Start', 'Stopp',\n",
      "       'Parkgebühren inkl. MwSt. in EUR', 'Status', 'Parkscheinart',\n",
      "       'Zonencode', 'Eigentümercode'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    print(automaten_df.columns)\n",
    "    print(app_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 1.2 - Zusammenführen und Formatieren (12 Punkte)\n",
    "Erstellen Sie einen DataFrame für beide Verkaufsarten, indem Sie die beiden zuvor erstellen DataFrames zusammenführen. Nutzen Sie dazu die Parkzonen Informationen *(in `parkzones_latlong.csv`)* und die Parkscheinautomatennummer *(in` pa_latlong.csv`)*. Stellen Sie sicher, dass sich in Ihrem DataFrame die geografischen Informationen für Parkscheinautomaten und Parkzonen befinden.\n",
    "Verwenden Sie die Spalten `Kaufdatum Lokal` und `Start` für das Kaufdatum, codieren Sie die Spalte als `datetime`-Objekt und verwenden Sie sie als Indexspalte. Stellen Sie außerdem sicher, dass die anderen Spalten ein angemessenes Datenformat haben.\n",
    "\n",
    "*Hinweis: Es ist zu erwarten, dass `Nan`-Werte für einige Spalten in den Zeilen zu Appkäufen auftauchen.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "\n",
    "data = { # define structure\n",
    "    'time': 'datetime64[ns]',\n",
    "    'machine_ID': pd.Int64Dtype(),\n",
    "    'fee': 'float64',\n",
    "    'category': 'object',\n",
    "    'street': 'object',\n",
    "    'latitude_machine': 'float64',\n",
    "    'longitude_machine': 'float64',\n",
    "    'zone': 'int64',\n",
    "    'latitude_zone': 'float64',\n",
    "    'longitude_zone': 'float64'}\n",
    "\n",
    "df = pd.DataFrame(columns=data.keys()).astype(data) # init dataframe\n",
    "df.set_index('time', inplace=True) # set index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge automaten_df into main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the overlapping row_name to string -> better to merge\n",
    "automaten_df['Automat - Automaten ID'] = automaten_df['Automat - Automaten ID'].astype(str)\n",
    "psa_info_df['PSA'] = psa_info_df['PSA'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp merge dataframe to create temp_df simpler and more structured\n",
    "temp_merged_df = pd.merge(automaten_df, psa_info_df, left_on='Automat - Automaten ID', right_on='PSA', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init temp df to merge better into main df\n",
    "temp_df = pd.DataFrame({\n",
    "    'time': pd.to_datetime(temp_merged_df['Kaufdatum Lokal'], format='%d.%m.%Y %H:%M:%S'),\n",
    "    'machine_ID': temp_merged_df['Automat - Automaten ID'].astype(int),\n",
    "    'fee': temp_merged_df['Betrag'],\n",
    "    'category': 'machine',\n",
    "    'street': temp_merged_df['location'],\n",
    "    'latitude_machine': temp_merged_df['latitude'],\n",
    "    'longitude_machine': temp_merged_df['longitude'],\n",
    "    'zone': temp_merged_df['zone'],\n",
    "    'latitude_zone': np.nan,\n",
    "    'longitude_zone': np.nan\n",
    "})\n",
    "\n",
    "temp_df.set_index('time', inplace=True) # set time as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     machine_ID  fee category                          street  \\\n",
      "time                                                                            \n",
      "2023-06-01 00:24:24          22  6.0  machine  Hospitalstraße / Nikolaistraße   \n",
      "2023-06-01 00:27:39          18  4.2  machine         Goethe-Allee / Neustadt   \n",
      "2023-06-01 00:36:00          76  1.0  machine                        Neustadt   \n",
      "2023-06-01 01:11:26          67  1.0  machine                     Lotzestraße   \n",
      "2023-06-01 02:17:35          75  3.5  machine                     Geiststraße   \n",
      "...                         ...  ...      ...                             ...   \n",
      "2023-11-30 21:36:45          12  7.0  machine                   Theaterstraße   \n",
      "2023-11-30 22:36:37          94  7.0  machine                 Friedrichstraße   \n",
      "2023-11-30 22:51:12          27  5.0  machine                  Albanikirchhof   \n",
      "2023-11-30 22:53:03          22  5.3  machine  Hospitalstraße / Nikolaistraße   \n",
      "2023-11-30 23:19:09          27  4.0  machine                  Albanikirchhof   \n",
      "\n",
      "                     latitude_machine  longitude_machine   zone  \\\n",
      "time                                                              \n",
      "2023-06-01 00:24:24         51.530052           9.932900  37001   \n",
      "2023-06-01 00:27:39         51.534737           9.930044  37001   \n",
      "2023-06-01 00:36:00         51.533328           9.929891  37001   \n",
      "2023-06-01 01:11:26         51.528634           9.934190  37005   \n",
      "2023-06-01 02:17:35         51.534089           9.928669  37001   \n",
      "...                               ...                ...    ...   \n",
      "2023-11-30 21:36:45         51.535157           9.938049  37001   \n",
      "2023-11-30 22:36:37         51.534008           9.938433  37001   \n",
      "2023-11-30 22:51:12         51.531921           9.942705  37001   \n",
      "2023-11-30 22:53:03         51.530052           9.932900  37001   \n",
      "2023-11-30 23:19:09         51.531921           9.942705  37001   \n",
      "\n",
      "                     latitude_zone  longitude_zone  \n",
      "time                                                \n",
      "2023-06-01 00:24:24            NaN             NaN  \n",
      "2023-06-01 00:27:39            NaN             NaN  \n",
      "2023-06-01 00:36:00            NaN             NaN  \n",
      "2023-06-01 01:11:26            NaN             NaN  \n",
      "2023-06-01 02:17:35            NaN             NaN  \n",
      "...                            ...             ...  \n",
      "2023-11-30 21:36:45            NaN             NaN  \n",
      "2023-11-30 22:36:37            NaN             NaN  \n",
      "2023-11-30 22:51:12            NaN             NaN  \n",
      "2023-11-30 22:53:03            NaN             NaN  \n",
      "2023-11-30 23:19:09            NaN             NaN  \n",
      "\n",
      "[708568 rows x 9 columns]\n",
      "machine_ID             int64\n",
      "fee                  float64\n",
      "category              object\n",
      "street                object\n",
      "latitude_machine     float64\n",
      "longitude_machine    float64\n",
      "zone                   int64\n",
      "latitude_zone        float64\n",
      "longitude_zone       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# debug\n",
    "if debug:\n",
    "    print(temp_df)\n",
    "    print(temp_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge temp_df into main df\n",
    "df = pd.concat([df, temp_df], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     machine_ID  fee category                          street  \\\n",
      "time                                                                            \n",
      "2023-06-01 00:24:24          22  6.0  machine  Hospitalstraße / Nikolaistraße   \n",
      "2023-06-01 00:27:39          18  4.2  machine         Goethe-Allee / Neustadt   \n",
      "2023-06-01 00:36:00          76  1.0  machine                        Neustadt   \n",
      "2023-06-01 01:11:26          67  1.0  machine                     Lotzestraße   \n",
      "2023-06-01 02:17:35          75  3.5  machine                     Geiststraße   \n",
      "...                         ...  ...      ...                             ...   \n",
      "2023-11-30 21:36:45          12  7.0  machine                   Theaterstraße   \n",
      "2023-11-30 22:36:37          94  7.0  machine                 Friedrichstraße   \n",
      "2023-11-30 22:51:12          27  5.0  machine                  Albanikirchhof   \n",
      "2023-11-30 22:53:03          22  5.3  machine  Hospitalstraße / Nikolaistraße   \n",
      "2023-11-30 23:19:09          27  4.0  machine                  Albanikirchhof   \n",
      "\n",
      "                     latitude_machine  longitude_machine   zone  \\\n",
      "time                                                              \n",
      "2023-06-01 00:24:24         51.530052           9.932900  37001   \n",
      "2023-06-01 00:27:39         51.534737           9.930044  37001   \n",
      "2023-06-01 00:36:00         51.533328           9.929891  37001   \n",
      "2023-06-01 01:11:26         51.528634           9.934190  37005   \n",
      "2023-06-01 02:17:35         51.534089           9.928669  37001   \n",
      "...                               ...                ...    ...   \n",
      "2023-11-30 21:36:45         51.535157           9.938049  37001   \n",
      "2023-11-30 22:36:37         51.534008           9.938433  37001   \n",
      "2023-11-30 22:51:12         51.531921           9.942705  37001   \n",
      "2023-11-30 22:53:03         51.530052           9.932900  37001   \n",
      "2023-11-30 23:19:09         51.531921           9.942705  37001   \n",
      "\n",
      "                     latitude_zone  longitude_zone  \n",
      "time                                                \n",
      "2023-06-01 00:24:24            NaN             NaN  \n",
      "2023-06-01 00:27:39            NaN             NaN  \n",
      "2023-06-01 00:36:00            NaN             NaN  \n",
      "2023-06-01 01:11:26            NaN             NaN  \n",
      "2023-06-01 02:17:35            NaN             NaN  \n",
      "...                            ...             ...  \n",
      "2023-11-30 21:36:45            NaN             NaN  \n",
      "2023-11-30 22:36:37            NaN             NaN  \n",
      "2023-11-30 22:51:12            NaN             NaN  \n",
      "2023-11-30 22:53:03            NaN             NaN  \n",
      "2023-11-30 23:19:09            NaN             NaN  \n",
      "\n",
      "[708568 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# debug\n",
    "if debug:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge app_df into main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp merge dataframe to create temp_df simpler and more structured\n",
    "merged_temp_df = pd.merge(app_df, parkzone_info_df, left_on='Parkzone', right_on='Zonencode', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init temp df to merge better into main df\n",
    "additional_df = pd.DataFrame({\n",
    "    'time': pd.to_datetime(merged_df['Start'], format='%Y-%m-%d %H:%M:%S'),\n",
    "    'machine_ID': pd.NA,\n",
    "    'fee': merged_df['Parkgebühren inkl. MwSt. in EUR'],\n",
    "    'category': 'app',\n",
    "    'street': np.nan,\n",
    "    'latitude_machine': np.nan,\n",
    "    'longitude_machine': np.nan,\n",
    "    'zone': merged_df['Parkzone'],\n",
    "    'latitude_zone': merged_df['latitude'],\n",
    "    'longitude_zone': merged_df['longitude']\n",
    "})\n",
    "\n",
    "additional_df.set_index('time', inplace=True)  # set time as index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Parkzone             Erstellt                Start  \\\n",
      "0          37010  2023-02-28 08:00:27  2023-02-28 08:00:27   \n",
      "1          37010  2023-02-28 09:29:55  2023-02-28 09:29:55   \n",
      "2          37010  2023-02-28 15:18:57  2023-02-28 15:18:57   \n",
      "3          37005  2023-02-28 16:38:33  2023-02-28 16:38:33   \n",
      "4          37005  2023-02-28 16:45:17  2023-02-28 16:45:17   \n",
      "...          ...                  ...                  ...   \n",
      "381273     37108  2023-05-31 19:39:53  2023-05-31 19:39:53   \n",
      "381274     37204  2023-05-31 19:46:03  2023-05-31 19:46:03   \n",
      "381275     37104  2023-05-31 19:58:45  2023-05-31 19:58:45   \n",
      "381276     37001  2023-05-31 22:29:05  2023-05-31 22:29:05   \n",
      "381277     37001  2023-05-31 22:33:09  2023-05-31 22:33:09   \n",
      "\n",
      "                      Stopp  Parkgebühren inkl. MwSt. in EUR     Status  \\\n",
      "0       2023-03-01 00:00:27                             4.00     normal   \n",
      "1       2023-03-01 09:29:55                             4.00     normal   \n",
      "2       2023-03-01 15:18:57                             4.00     normal   \n",
      "3       2023-03-01 10:20:00                             3.28     normal   \n",
      "4       2023-03-01 07:45:17                             1.57     normal   \n",
      "...                     ...                              ...        ...   \n",
      "381273  2023-05-31 20:17:27                              NaN     normal   \n",
      "381274  2023-05-31 19:52:59                              NaN     normal   \n",
      "381275  2023-05-31 23:43:53                              NaN     normal   \n",
      "381276  2023-05-31 22:29:38                              NaN  storniert   \n",
      "381277  2023-05-31 22:33:28                              NaN  storniert   \n",
      "\n",
      "       Parkscheinart  Zonencode_x Eigentümercode   latitude  longitude  \\\n",
      "0           Kurzzeit        37010                 51.553603   9.942338   \n",
      "1           Kurzzeit        37010                 51.553603   9.942338   \n",
      "2           Kurzzeit        37010                 51.553603   9.942338   \n",
      "3           Kurzzeit        37005                 51.531270   9.936706   \n",
      "4           Kurzzeit        37005                 51.531270   9.936706   \n",
      "...              ...          ...            ...        ...        ...   \n",
      "381273      Kurzzeit        37108                 51.536733   9.928201   \n",
      "381274      Kurzzeit        37204                 51.540630   9.935538   \n",
      "381275      Kurzzeit        37104                 51.536634   9.932465   \n",
      "381276      Kurzzeit        37001                 51.534248   9.936501   \n",
      "381277      Kurzzeit        37001                 51.534248   9.936501   \n",
      "\n",
      "        Zonencode_y                                            Bereich  \\\n",
      "0             37010         Parkzone II - Am Papenberg, Zimmermannstr.   \n",
      "1             37010         Parkzone II - Am Papenberg, Zimmermannstr.   \n",
      "2             37010         Parkzone II - Am Papenberg, Zimmermannstr.   \n",
      "3             37005                Parkzone II - Straßenrandparkplätze   \n",
      "4             37005                Parkzone II - Straßenrandparkplätze   \n",
      "...             ...                                                ...   \n",
      "381273        37108                 Parkzone I - Parkplatz Bahnhof Ost   \n",
      "381274        37204  Parkzone II - Parkplatz Platz der Göttinger Si...   \n",
      "381275        37104             Parkzone I - Parkplatz Reitstallstraße   \n",
      "381276        37001                 Parkzone I - Straßenrandparkplätze   \n",
      "381277        37001                 Parkzone I - Straßenrandparkplätze   \n",
      "\n",
      "       Höchstparkdauer  \n",
      "0          Tagesticket  \n",
      "1          Tagesticket  \n",
      "2          Tagesticket  \n",
      "3            4 Stunden  \n",
      "4            4 Stunden  \n",
      "...                ...  \n",
      "381273        1 Stunde  \n",
      "381274       8 Stunden  \n",
      "381275       4 Stunden  \n",
      "381276       4 Stunden  \n",
      "381277       4 Stunden  \n",
      "\n",
      "[381278 rows x 14 columns]\n",
      "Parkzone                             int64\n",
      "Erstellt                            object\n",
      "Start                               object\n",
      "Stopp                               object\n",
      "Parkgebühren inkl. MwSt. in EUR    float64\n",
      "Status                              object\n",
      "Parkscheinart                       object\n",
      "Zonencode_x                          int64\n",
      "Eigentümercode                      object\n",
      "latitude                           float64\n",
      "longitude                          float64\n",
      "Zonencode_y                          int64\n",
      "Bereich                             object\n",
      "Höchstparkdauer                     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# debug\n",
    "if debug:\n",
    "    print(merged_temp_df)\n",
    "    print(merged_temp_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/41/npg4cjr50qqgztp8lxq5frbh0000gn/T/ipykernel_89465/2480545326.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, additional_df], ignore_index=False)\n"
     ]
    }
   ],
   "source": [
    "# merge temp_df into main df\n",
    "df = pd.concat([df, additional_df], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     machine_ID  fee category                          street  \\\n",
      "time                                                                            \n",
      "2023-06-01 00:24:24          22  6.0  machine  Hospitalstraße / Nikolaistraße   \n",
      "2023-06-01 00:27:39          18  4.2  machine         Goethe-Allee / Neustadt   \n",
      "2023-06-01 00:36:00          76  1.0  machine                        Neustadt   \n",
      "2023-06-01 01:11:26          67  1.0  machine                     Lotzestraße   \n",
      "2023-06-01 02:17:35          75  3.5  machine                     Geiststraße   \n",
      "...                         ...  ...      ...                             ...   \n",
      "2023-05-31 19:39:53        <NA>  NaN      app                             NaN   \n",
      "2023-05-31 19:46:03        <NA>  NaN      app                             NaN   \n",
      "2023-05-31 19:58:45        <NA>  NaN      app                             NaN   \n",
      "2023-05-31 22:29:05        <NA>  NaN      app                             NaN   \n",
      "2023-05-31 22:33:09        <NA>  NaN      app                             NaN   \n",
      "\n",
      "                     latitude_machine  longitude_machine   zone  \\\n",
      "time                                                              \n",
      "2023-06-01 00:24:24         51.530052           9.932900  37001   \n",
      "2023-06-01 00:27:39         51.534737           9.930044  37001   \n",
      "2023-06-01 00:36:00         51.533328           9.929891  37001   \n",
      "2023-06-01 01:11:26         51.528634           9.934190  37005   \n",
      "2023-06-01 02:17:35         51.534089           9.928669  37001   \n",
      "...                               ...                ...    ...   \n",
      "2023-05-31 19:39:53               NaN                NaN  37108   \n",
      "2023-05-31 19:46:03               NaN                NaN  37204   \n",
      "2023-05-31 19:58:45               NaN                NaN  37104   \n",
      "2023-05-31 22:29:05               NaN                NaN  37001   \n",
      "2023-05-31 22:33:09               NaN                NaN  37001   \n",
      "\n",
      "                     latitude_zone  longitude_zone  \n",
      "time                                                \n",
      "2023-06-01 00:24:24            NaN             NaN  \n",
      "2023-06-01 00:27:39            NaN             NaN  \n",
      "2023-06-01 00:36:00            NaN             NaN  \n",
      "2023-06-01 01:11:26            NaN             NaN  \n",
      "2023-06-01 02:17:35            NaN             NaN  \n",
      "...                            ...             ...  \n",
      "2023-05-31 19:39:53      51.536733        9.928201  \n",
      "2023-05-31 19:46:03      51.540630        9.935538  \n",
      "2023-05-31 19:58:45      51.536634        9.932465  \n",
      "2023-05-31 22:29:05      51.534248        9.936501  \n",
      "2023-05-31 22:33:09      51.534248        9.936501  \n",
      "\n",
      "[1089846 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# debug\n",
    "if debug:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 1.3 - DataFrame Check (2 Punkte)\n",
    "Der bereinigte und vollständige DataFrame für die folgenden Aufgaben sollte der Datei `data/clean_dataframe.csv` entsprechen, der wie folgt eingelesen werden kann:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and Sort clean_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.read_csv('data/clean_dataframe.csv', parse_dates=['time'], index_col='time', dtype={\n",
    "                                                                            'machine_ID': 'Int64', \n",
    "                                                                            'fee': 'float64', \n",
    "                                                                            'category': 'object', \n",
    "                                                                            'street': 'object', \n",
    "                                                                            'latitude_machine': 'float64', \n",
    "                                                                            'longitude_machine': 'float64', \n",
    "                                                                            'zone': 'int64', \n",
    "                                                                            'latitude_zone': 'float64', \n",
    "                                                                            'longitude_zone': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-01-31 13:07:44', '2023-01-31 15:40:23',\n",
       "               '2023-01-31 15:48:59', '2023-01-31 15:58:47',\n",
       "               '2023-01-31 16:08:00', '2023-01-31 16:15:06',\n",
       "               '2023-01-31 16:23:04', '2023-01-31 16:30:19',\n",
       "               '2023-01-31 16:41:42', '2023-01-31 16:48:04',\n",
       "               ...\n",
       "               '2023-12-31 14:51:53', '2023-12-31 15:24:17',\n",
       "               '2023-12-31 15:45:50', '2023-12-31 16:35:23',\n",
       "               '2023-12-31 16:43:56', '2023-12-31 16:45:25',\n",
       "               '2023-12-31 17:09:16', '2023-12-31 17:25:59',\n",
       "               '2023-12-31 17:52:09', '2023-12-31 20:40:11'],\n",
       "              dtype='datetime64[ns]', name='time', length=1089846, freq=None)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     machine_ID   fee category street  latitude_machine  \\\n",
      "time                                                                      \n",
      "2023-01-31 13:07:44        <NA>  8.31      app    NaN               NaN   \n",
      "2023-01-31 15:40:23        <NA>  4.96      app    NaN               NaN   \n",
      "2023-01-31 15:48:59        <NA>  4.74      app    NaN               NaN   \n",
      "2023-01-31 15:58:47        <NA>  7.53      app    NaN               NaN   \n",
      "2023-01-31 16:08:00        <NA>  4.30      app    NaN               NaN   \n",
      "...                         ...   ...      ...    ...               ...   \n",
      "2023-12-31 16:45:25        <NA>  0.00      app    NaN               NaN   \n",
      "2023-12-31 17:09:16        <NA>  0.00      app    NaN               NaN   \n",
      "2023-12-31 17:25:59        <NA>  0.00      app    NaN               NaN   \n",
      "2023-12-31 17:52:09        <NA>  0.00      app    NaN               NaN   \n",
      "2023-12-31 20:40:11        <NA>  0.00      app    NaN               NaN   \n",
      "\n",
      "                     longitude_machine   zone  latitude_zone  longitude_zone  \n",
      "time                                                                          \n",
      "2023-01-31 13:07:44                NaN  37008      51.541762        9.942282  \n",
      "2023-01-31 15:40:23                NaN  37005      51.531270        9.936706  \n",
      "2023-01-31 15:48:59                NaN  37005      51.531270        9.936706  \n",
      "2023-01-31 15:58:47                NaN  37204      51.540630        9.935538  \n",
      "2023-01-31 16:08:00                NaN  37105      51.529205        9.933063  \n",
      "...                                ...    ...            ...             ...  \n",
      "2023-12-31 16:45:25                NaN  37108      51.536733        9.928201  \n",
      "2023-12-31 17:09:16                NaN  37001      51.534248        9.936501  \n",
      "2023-12-31 17:25:59                NaN  37105      51.529205        9.933063  \n",
      "2023-12-31 17:52:09                NaN  37001      51.534248        9.936501  \n",
      "2023-12-31 20:40:11                NaN  37108      51.536733        9.928201  \n",
      "\n",
      "[1089846 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "if debug: print(df_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = df_compare.sort_values(by=['time', 'fee', 'zone', 'machine_ID'])\n",
    "df = df.sort_values(by=['time', 'fee', 'zone', 'machine_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     machine_ID   fee category street  latitude_machine  \\\n",
      "time                                                                      \n",
      "2023-01-31 13:07:44        <NA>  8.31      app    NaN               NaN   \n",
      "2023-01-31 15:40:23        <NA>  4.96      app    NaN               NaN   \n",
      "2023-01-31 15:48:59        <NA>  4.74      app    NaN               NaN   \n",
      "2023-01-31 15:58:47        <NA>  7.53      app    NaN               NaN   \n",
      "2023-01-31 16:08:00        <NA>  4.30      app    NaN               NaN   \n",
      "...                         ...   ...      ...    ...               ...   \n",
      "2023-12-31 16:45:25        <NA>   NaN      app    NaN               NaN   \n",
      "2023-12-31 17:09:16        <NA>   NaN      app    NaN               NaN   \n",
      "2023-12-31 17:25:59        <NA>   NaN      app    NaN               NaN   \n",
      "2023-12-31 17:52:09        <NA>   NaN      app    NaN               NaN   \n",
      "2023-12-31 20:40:11        <NA>   NaN      app    NaN               NaN   \n",
      "\n",
      "                     longitude_machine   zone  latitude_zone  longitude_zone  \n",
      "time                                                                          \n",
      "2023-01-31 13:07:44                NaN  37008      51.541762        9.942282  \n",
      "2023-01-31 15:40:23                NaN  37005      51.531270        9.936706  \n",
      "2023-01-31 15:48:59                NaN  37005      51.531270        9.936706  \n",
      "2023-01-31 15:58:47                NaN  37204      51.540630        9.935538  \n",
      "2023-01-31 16:08:00                NaN  37105      51.529205        9.933063  \n",
      "...                                ...    ...            ...             ...  \n",
      "2023-12-31 16:45:25                NaN  37108      51.536733        9.928201  \n",
      "2023-12-31 17:09:16                NaN  37001      51.534248        9.936501  \n",
      "2023-12-31 17:25:59                NaN  37105      51.529205        9.933063  \n",
      "2023-12-31 17:52:09                NaN  37001      51.534248        9.936501  \n",
      "2023-12-31 20:40:11                NaN  37108      51.536733        9.928201  \n",
      "\n",
      "[1089846 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     machine_ID   fee category street  latitude_machine  \\\n",
      "time                                                                      \n",
      "2023-01-31 13:07:44        <NA>  8.31      app    NaN               NaN   \n",
      "2023-01-31 15:40:23        <NA>  4.96      app    NaN               NaN   \n",
      "2023-01-31 15:48:59        <NA>  4.74      app    NaN               NaN   \n",
      "2023-01-31 15:58:47        <NA>  7.53      app    NaN               NaN   \n",
      "2023-01-31 16:08:00        <NA>  4.30      app    NaN               NaN   \n",
      "...                         ...   ...      ...    ...               ...   \n",
      "2023-12-31 16:45:25        <NA>  0.00      app    NaN               NaN   \n",
      "2023-12-31 17:09:16        <NA>  0.00      app    NaN               NaN   \n",
      "2023-12-31 17:25:59        <NA>  0.00      app    NaN               NaN   \n",
      "2023-12-31 17:52:09        <NA>  0.00      app    NaN               NaN   \n",
      "2023-12-31 20:40:11        <NA>  0.00      app    NaN               NaN   \n",
      "\n",
      "                     longitude_machine   zone  latitude_zone  longitude_zone  \n",
      "time                                                                          \n",
      "2023-01-31 13:07:44                NaN  37008      51.541762        9.942282  \n",
      "2023-01-31 15:40:23                NaN  37005      51.531270        9.936706  \n",
      "2023-01-31 15:48:59                NaN  37005      51.531270        9.936706  \n",
      "2023-01-31 15:58:47                NaN  37204      51.540630        9.935538  \n",
      "2023-01-31 16:08:00                NaN  37105      51.529205        9.933063  \n",
      "...                                ...    ...            ...             ...  \n",
      "2023-12-31 16:45:25                NaN  37108      51.536733        9.928201  \n",
      "2023-12-31 17:09:16                NaN  37001      51.534248        9.936501  \n",
      "2023-12-31 17:25:59                NaN  37105      51.529205        9.933063  \n",
      "2023-12-31 17:52:09                NaN  37001      51.534248        9.936501  \n",
      "2023-12-31 20:40:11                NaN  37108      51.536733        9.928201  \n",
      "\n",
      "[1089846 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "if debug: print(df_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### compare dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Unterschiede in der Spalte 'machine_ID':\n",
      "                     self  other\n",
      "time                            \n",
      "2023-04-01 13:11:25    55    214\n",
      "2023-04-04 14:40:08    22     18\n",
      "2023-04-04 15:50:55    23    225\n",
      "2023-04-04 16:48:39    10     18\n",
      "2023-04-05 17:49:58    94     55\n",
      "...                   ...    ...\n",
      "2023-12-19 11:15:36   309    218\n",
      "2023-12-19 14:33:04    42     53\n",
      "2023-12-20 10:19:47    55     80\n",
      "2023-12-21 09:16:38    80     29\n",
      "2023-12-21 14:17:54    92      3\n",
      "\n",
      "[280 rows x 2 columns]\n",
      "\n",
      "Unterschiede in der Spalte 'fee':\n",
      "                     self  other\n",
      "time                            \n",
      "2023-04-01 08:27:01   2.8   0.70\n",
      "2023-04-01 09:33:25   3.2   1.82\n",
      "2023-04-01 09:41:32   2.0   1.50\n",
      "2023-04-01 10:08:57   2.6   0.50\n",
      "2023-04-01 10:19:05   3.0   1.13\n",
      "...                   ...    ...\n",
      "2023-12-29 14:44:08   1.0   0.00\n",
      "2023-12-29 14:55:43   1.7   0.00\n",
      "2023-12-29 15:04:11   4.0   0.00\n",
      "2023-12-29 15:20:26   3.0   0.00\n",
      "2023-12-29 15:23:46   1.2   0.00\n",
      "\n",
      "[9792 rows x 2 columns]\n",
      "\n",
      "Unterschiede in der Spalte 'category':\n",
      "                        self    other\n",
      "time                                 \n",
      "2023-04-01 08:27:01  machine      app\n",
      "2023-04-01 08:27:01      app  machine\n",
      "2023-04-01 09:33:25  machine      app\n",
      "2023-04-01 09:33:25      app  machine\n",
      "2023-04-01 09:41:32  machine      app\n",
      "...                      ...      ...\n",
      "2023-12-29 15:04:11      app  machine\n",
      "2023-12-29 15:20:26  machine      app\n",
      "2023-12-29 15:20:26      app  machine\n",
      "2023-12-29 15:23:46  machine      app\n",
      "2023-12-29 15:23:46      app  machine\n",
      "\n",
      "[19586 rows x 2 columns]\n",
      "\n",
      "Unterschiede in der Spalte 'street':\n",
      "                                               self  \\\n",
      "time                                                  \n",
      "2023-04-01 13:11:25      Platz der Göttinger Sieben   \n",
      "2023-04-04 14:40:08  Hospitalstraße / Nikolaistraße   \n",
      "2023-04-04 15:50:55                    Goethe-Allee   \n",
      "2023-04-04 16:48:39      Friedrichstraße / Postberg   \n",
      "2023-04-05 17:49:58                 Friedrichstraße   \n",
      "...                                             ...   \n",
      "2023-12-19 11:15:36                   Arndtstraße 2   \n",
      "2023-12-19 14:33:04            Lange-Geismar-Straße   \n",
      "2023-12-20 10:19:47      Platz der Göttinger Sieben   \n",
      "2023-12-21 09:16:38                  Maschmühlenweg   \n",
      "2023-12-21 14:17:54                Voigt-Realschule   \n",
      "\n",
      "                                          other  \n",
      "time                                             \n",
      "2023-04-01 13:11:25                Wöhlerstraße  \n",
      "2023-04-04 14:40:08     Goethe-Allee / Neustadt  \n",
      "2023-04-04 15:50:55                Planckstraße  \n",
      "2023-04-04 16:48:39     Goethe-Allee / Neustadt  \n",
      "2023-04-05 17:49:58  Platz der Göttinger Sieben  \n",
      "...                                         ...  \n",
      "2023-12-19 11:15:36        Wilhelm-Weber-Straße  \n",
      "2023-12-19 14:33:04  Platz der Göttinger Sieben  \n",
      "2023-12-20 10:19:47              Maschmühlenweg  \n",
      "2023-12-21 09:16:38  Rathaus - Außenstellplätze  \n",
      "2023-12-21 14:17:54                   Papendiek  \n",
      "\n",
      "[279 rows x 2 columns]\n",
      "\n",
      "Unterschiede in der Spalte 'latitude_machine':\n",
      "                          self      other\n",
      "time                                     \n",
      "2023-04-01 13:11:25  51.540630  51.537750\n",
      "2023-04-04 14:40:08  51.530052  51.534737\n",
      "2023-04-04 15:50:55  51.535325  51.536706\n",
      "2023-04-04 16:48:39  51.534699  51.534737\n",
      "2023-04-05 17:49:58  51.534008  51.540630\n",
      "...                        ...        ...\n",
      "2023-12-19 11:15:36  51.546201  51.538692\n",
      "2023-12-19 14:33:04  51.531695  51.540630\n",
      "2023-12-20 10:19:47  51.540630  51.544763\n",
      "2023-12-21 09:16:38  51.544763  51.528115\n",
      "2023-12-21 14:17:54  51.531365  51.533827\n",
      "\n",
      "[279 rows x 2 columns]\n",
      "\n",
      "Unterschiede in der Spalte 'longitude_machine':\n",
      "                         self     other\n",
      "time                                   \n",
      "2023-04-01 13:11:25  9.935538  9.941432\n",
      "2023-04-04 14:40:08  9.932900  9.930044\n",
      "2023-04-04 15:50:55  9.931286  9.943673\n",
      "2023-04-04 16:48:39  9.940698  9.930044\n",
      "2023-04-05 17:49:58  9.938433  9.935538\n",
      "...                       ...       ...\n",
      "2023-12-19 11:15:36  9.932023  9.940054\n",
      "2023-12-19 14:33:04  9.936737  9.935538\n",
      "2023-12-20 10:19:47  9.935538  9.924276\n",
      "2023-12-21 09:16:38  9.924276  9.940574\n",
      "2023-12-21 14:17:54  9.927962  9.931693\n",
      "\n",
      "[279 rows x 2 columns]\n",
      "\n",
      "Unterschiede in der Spalte 'zone':\n",
      "                        self    other\n",
      "time                                 \n",
      "2023-04-01 08:27:01  37001.0  37101.0\n",
      "2023-04-01 08:27:01  37101.0  37001.0\n",
      "2023-04-01 09:33:25  37205.0  37001.0\n",
      "2023-04-01 09:33:25  37001.0  37205.0\n",
      "2023-04-01 09:41:32  37106.0  37105.0\n",
      "...                      ...      ...\n",
      "2023-12-29 14:55:43  37204.0  37106.0\n",
      "2023-12-29 15:04:11  37001.0  37005.0\n",
      "2023-12-29 15:04:11  37005.0  37001.0\n",
      "2023-12-29 15:23:46  37108.0  37106.0\n",
      "2023-12-29 15:23:46  37106.0  37108.0\n",
      "\n",
      "[20384 rows x 2 columns]\n",
      "\n",
      "Unterschiede in der Spalte 'latitude_zone':\n",
      "                          self      other\n",
      "time                                     \n",
      "2023-04-01 08:27:01  51.529542  51.534248\n",
      "2023-04-01 09:33:25  51.534248  51.537585\n",
      "2023-04-01 09:41:32  51.529205  51.530127\n",
      "2023-04-01 10:08:57  51.531270  51.534248\n",
      "2023-04-01 10:19:05  51.530127  51.534248\n",
      "...                        ...        ...\n",
      "2023-12-29 12:51:27  51.534248  51.533104\n",
      "2023-12-29 14:00:23  51.537675  51.534248\n",
      "2023-12-29 14:55:43  51.540630  51.530127\n",
      "2023-12-29 15:04:11  51.531270  51.534248\n",
      "2023-12-29 15:23:46  51.530127  51.536733\n",
      "\n",
      "[12388 rows x 2 columns]\n",
      "\n",
      "Unterschiede in der Spalte 'longitude_zone':\n",
      "                         self     other\n",
      "time                                   \n",
      "2023-04-01 08:27:01  9.939956  9.936501\n",
      "2023-04-01 09:33:25  9.936501  9.940781\n",
      "2023-04-01 09:41:32  9.933063  9.937980\n",
      "2023-04-01 10:08:57  9.936706  9.936501\n",
      "2023-04-01 10:19:05  9.937980  9.936501\n",
      "...                       ...       ...\n",
      "2023-12-29 12:51:27  9.936501  9.926817\n",
      "2023-12-29 14:00:23  9.930298  9.936501\n",
      "2023-12-29 14:55:43  9.935538  9.937980\n",
      "2023-12-29 15:04:11  9.936706  9.936501\n",
      "2023-12-29 15:23:46  9.937980  9.928201\n",
      "\n",
      "[12388 rows x 2 columns]\n",
      "\n",
      "                    machine_ID        fee       category       street        \\\n",
      "                          self other self other     self other   self other   \n",
      "time                                                                          \n",
      "2023-02-01 04:01:58       <NA>  <NA>  NaN   NaN      NaN   NaN    NaN   NaN   \n",
      "2023-02-01 04:14:33       <NA>  <NA>  NaN   NaN      NaN   NaN    NaN   NaN   \n",
      "2023-02-01 04:34:04       <NA>  <NA>  NaN   NaN      NaN   NaN    NaN   NaN   \n",
      "2023-02-01 05:02:39       <NA>  <NA>  NaN   NaN      NaN   NaN    NaN   NaN   \n",
      "2023-02-01 05:07:01       <NA>  <NA>  NaN   NaN      NaN   NaN    NaN   NaN   \n",
      "...                        ...   ...  ...   ...      ...   ...    ...   ...   \n",
      "2023-12-31 16:45:25       <NA>  <NA>  NaN   0.0      NaN   NaN    NaN   NaN   \n",
      "2023-12-31 17:09:16       <NA>  <NA>  NaN   0.0      NaN   NaN    NaN   NaN   \n",
      "2023-12-31 17:25:59       <NA>  <NA>  NaN   0.0      NaN   NaN    NaN   NaN   \n",
      "2023-12-31 17:52:09       <NA>  <NA>  NaN   0.0      NaN   NaN    NaN   NaN   \n",
      "2023-12-31 20:40:11       <NA>  <NA>  NaN   0.0      NaN   NaN    NaN   NaN   \n",
      "\n",
      "                    latitude_machine       longitude_machine       zone        \\\n",
      "                                self other              self other self other   \n",
      "time                                                                            \n",
      "2023-02-01 04:01:58              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "2023-02-01 04:14:33              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "2023-02-01 04:34:04              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "2023-02-01 05:02:39              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "2023-02-01 05:07:01              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "...                              ...   ...               ...   ...  ...   ...   \n",
      "2023-12-31 16:45:25              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "2023-12-31 17:09:16              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "2023-12-31 17:25:59              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "2023-12-31 17:52:09              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "2023-12-31 20:40:11              NaN   NaN               NaN   NaN  NaN   NaN   \n",
      "\n",
      "                    latitude_zone            longitude_zone            \n",
      "                             self      other           self     other  \n",
      "time                                                                   \n",
      "2023-02-01 04:01:58           NaN  51.541762            NaN  9.942282  \n",
      "2023-02-01 04:14:33           NaN  51.541762            NaN  9.942282  \n",
      "2023-02-01 04:34:04           NaN  51.553603            NaN  9.942338  \n",
      "2023-02-01 05:02:39           NaN  51.541762            NaN  9.942282  \n",
      "2023-02-01 05:07:01           NaN  51.534248            NaN  9.936501  \n",
      "...                           ...        ...            ...       ...  \n",
      "2023-12-31 16:45:25           NaN        NaN            NaN       NaN  \n",
      "2023-12-31 17:09:16           NaN        NaN            NaN       NaN  \n",
      "2023-12-31 17:25:59           NaN        NaN            NaN       NaN  \n",
      "2023-12-31 17:52:09           NaN        NaN            NaN       NaN  \n",
      "2023-12-31 20:40:11           NaN        NaN            NaN       NaN  \n",
      "\n",
      "[1026375 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.equals(df_compare))\n",
    "\n",
    "# Unterschiede anzeigen\n",
    "differences = df.compare(df_compare)\n",
    "\n",
    "for col in differences.columns.levels[0]:\n",
    "    diff = differences[col]\n",
    "    if not diff.dropna().empty:\n",
    "        print(f\"Unterschiede in der Spalte '{col}':\")\n",
    "        print(diff.dropna())\n",
    "        print()\n",
    "        \n",
    "# Ergebnis anzeigen\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stellen Sie sicher, dass Ihr DataFrame mit `clean_dataframe.csv` übereinstimmt. Verwenden Sie dazu die Funktion [`pandas.DataFrame.equals`](https://pandas.pydata.org/docs/reference/api/pandas.dataframe.equals.html).\n",
    "\n",
    "Sollte `pandas.DataFrame.equals` nach Ihren Anpassungen nicht `True` zurückgeben, arbeiten Sie bitte mit `clean_dataframe.csv` weiter und geben Sie dies in einer Markdown-Zelle an. In diesem Fall erhalten Sie keine Punkte für die Teilaufgabe 1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## Aufgabe 2: Plotting (38 Punkte)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.1 - Analyse der Parkscheinautomaten (11 Punkte)\n",
    "Die Stadt Göttingen möchte einen Überblick über die Umsätze der einzelnen **Parkscheinautomaten** erhalten und stellt Sie für eine anfängliche explorative Analyse des Verkaufsvolumens und der geografischen Anordnung der Automaten ein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 (6 Punkte)\n",
    "Finden Sie die fünf umsatzstärksten Parkscheinautomaten im Jahr 2023 und visualisieren Sie den **wöchentlichen** Umsatz im Laufe des Jahres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 (5 Punkte)\n",
    "Der Standort der Parkscheinautomaten könnte auch einen Einfluss auf deren Umsatz haben.\n",
    "\n",
    "Machen Sie sich mit der Funktion `plot_map` aus der Bibliothek `dsplotter` vertraut. Verwenden Sie die Funktion, um den jährlichen Umsatz für jeden Automaten auf einer Karte zu visualisieren. Machen Sie die Farbe **und** den Radius der Standortmarkierung abhängig vom jährlichen Umsatz. Was haben Automaten mit einem hohen jährlichen Umsatz gemeinsam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.2 - Analyse der Automaten- und Appnutzung pro Parkzone (27 Punkte)\n",
    "Im Rahmen der Digitalisierungsinitiative der Stadt wurde die Parkster-App vor einigen Jahren als Alternative zu Parkscheinautomaten eingeführt.\n",
    "Bisher wurden nur die Parkscheinautomaten in die Analyse eingeschlossen und daher einen Großteil des Ticketverkaufs, der über die App stattfand, nicht beachtet.\n",
    "\n",
    "Die Stadt möchte für 2023 eine erste visuelle Analyse der Akzeptanz der App in den einzelnen Parkzonen durchführen und anschließend den gesamten Umsatz analysieren.\n",
    "\n",
    "*Hinweis: Beachten Sie, dass wir die Umsätze aus der Appnutzung nur einschließen können, indem wir die Gesamtauswertung auf Ebene der Parkzonen durchführen.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 (6 Punkte)\n",
    "Bevorzugen Parkende die App- oder die Parkscheinautomatennutzung? \n",
    "\n",
    "Verwenden Sie einen geeigneten Plot, um die durchschnittliche Automaten- bzw. Appnutzungsrate pro **Parkzone** für das gesamte Jahr 2023 zu visualisieren. Was können Sie dem Plot entnehmen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 (9 Punkte)\n",
    "Wie stark werden die einzelnen Parkzonen genutzt? \n",
    "\n",
    "Visualisieren Sie die Gesamtzahl der Verkäufe und die Automaten- bzw. Appnutzungrate für jede Parkzone im Jahr 2023 **in einem Diagramm**. Verwenden Sie für die y-Achse eine `log`-Skalierung. Was können Sie dem Plot entnehmen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 (7 Punkte)\n",
    "Der vorherige Plot gibt uns eine Vorstellung von der Gesamtzahl der Parktickets *pro Parkzone*. Diese korreliert sehr wahrscheinlich stark mit der Anzahl der Parkplätze pro Zone. Um Parkzonen mit einer unterschiedlichen Anzahl an Parkplätzen zu vergleichen, sollten wir diese mithilfe der Anzahl der verfügbaren Parkplätze je Zone relativieren. Auf diese Weise können wir herausfinden, welche Zonen, relativ zu ihrer Größe, am häufigsten verwendet werden. Da wir nicht die Anzahl der Parkplätze für jede Zone zur Verfügung haben, können wir nur die Anzahl der Parkscheinautomaten als grobe Annäherung verwenden. \n",
    "\n",
    "Verwenden Sie die Informationen aus `psa_latlong.csv` und reproduzieren Sie den vorherigen mit Plot der Gesamtzahl der Verkäufe pro Automat für jede Parkzone. Verwenden Sie für die y-Achse eine `log`-Skalierung. Welche Parkzone wird am meisten genutzt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 (5 Punkte)\n",
    "Bisher haben wir die geografischen Informationen der Parkzonen nicht mit einbezogen. \n",
    "\n",
    "Verwenden Sie erneut die Funktion `plot_map`, um den Standort aller Parkzonen, ihre durchschnittlichen Tickets pro Automat und die Automaten- bzw. Appnutzungsrate zu visualieren. Färben Sie den Kartenmarker mithilfe der Automaten- bzw. Appnutzungsrate und legen Sie den Radius mit den durschnittlich verkauften Tickets pro Automat fest. Was können Sie der Darstellung entnehmen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aufgabe 3: Statistics (18 Punkte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 3.1 - t-Test (13 Punkte)\n",
    "Zusätzlich zu der visuellen Analyse möchte die Stadt nun auch eine statistische Untersuchung der Verwendung von Parkscheinautomaten und Apps durchführen.\n",
    "\n",
    "Bestimmen Sie dazu zunächst die Automaten- bzw. Appnutzungsrate pro Parkzone für jeden Kalendertag. Führen Sie anschließend für **jede Parkzone** einen t-Test durch, der testet, ob Parkende es vorziehen die App in der jeweiligen Zone zu verwenden. Schreiben Sie das entsprechende Hypothesenpaar auf, führen Sie den Test durch und interpretieren Sie Ihre Testergebnisse. Verwenden Sie für Ihre Testentscheidung ein Signifikanzniveau von 0.05. Welche grundlegende Annahme von statistischen Tests könnte bei diesem Vorgehen verletzt werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 3.2 - Statistisches Verständnis (5 Punkte)\n",
    "Angenommen, für die Zone `37106` beträgt die durchschnittliche Automaten- bzw. Appnutzungsrate `0.5`.\n",
    "Die Stadt sendet Ihnen die Daten für 2024. \n",
    "\n",
    "An wie vielen Tagen können Sie erwarten, dass die Appnutzung signifikant höher ist, wenn Sie weiterhin von einem Signifikanzniveau von `0.05` ausgehen? Erklären Sie, warum dies der Fall ist. Nehmen Sie an, dass sich das Verhalten der Parkenden im Vergleich zu 2023 nicht geändert hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aufgabe 4: Machine Learning (20 Punkte)\n",
    "\n",
    "Nutzen Sie ein K-Nearest-Neighbors (KNN) Modell, um die Automaten- bzw. Appnutzungsrate mithilfe des Standortes (`latitude`, `longitude`) und der Parkgebühr (`fee`) vorherzusagen. Verwenden Sie ausschließlich Datenreihen mit Parkgebühren zwischen 2 Euro und 7 Euro.\n",
    "\n",
    "#### Aufgabe 4.1 - Modell-Training and Hyperparameter-Suche (10 Punkte)\n",
    "Bereiten Sie die Daten sinnvoll auf, führen Sie eine Hyperparameter-Suche nach optimalem K-Wert aus, visualisieren Sie die Ergebnisse der Hyperparameter-Suche und verwenden Sie schließlich Ihren optimalen K-Wert, um das Modell zu trainieren.\n",
    "\n",
    "*Hinweis: Verwenden Sie 30% aller Daten zur Bestimmung des optimalen K-Wertes, um die Hyperparameter-Suche zu beschleunigen, und den gesamten Datensatz für das Modell-Training.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 4.2 - Visualisierung der Modell-Vorhersage (10 Punkte)\n",
    "Erstellen Sie ein `100 x 100` Grid aus Längen-/Breitengradwerten unter Verwendung der minimalen und maximalen Werte in Ihrem Datensatz. Visualisieren Sie die Vorhersagen des KNN-Modells **für drei verschiedene Parkgebühren** - 3, 5 und 7 Euro. Verwenden Sie dazu die Funktion `plot_map`. Färben Sie den Marker entsprechend der Modell-Vorhersage. Beschreiben Sie mindestens 2 visuelle Veränderungen des vorhergesagten Nutzungsmusters auf der Karte."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
